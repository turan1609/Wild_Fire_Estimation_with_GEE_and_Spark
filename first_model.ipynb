{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69db3cb7-0e72-43f2-940b-605ac2181323",
   "metadata": {},
   "source": [
    "## Model Training Preparation (PySpark)\n",
    "\n",
    "In this step, we initialize a local Spark session and prepare the final dataset\n",
    "for machine learning. Feature columns are assembled into a single feature vector,\n",
    "and the dataset is split into training and test sets for model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e06610-dd8a-4a53-8eb1-0147e07e2f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EÄŸitim Verisi: 296136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================>                   (2 + 1) / 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Verisi: 73964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALAZ_Training_Phase\") \\\n",
    "    .master(\"local[3]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.parquet(\"../data/processed/ALAZ_Final_Dataset_Cleaned.parquet\")\n",
    "\n",
    "feature_cols = [\n",
    "    'yukselti', 'egim', 'baki',\n",
    "    'sicaklik', 'ruzgar_hizi', 'bagil_nem', 'yagis', 'toprak_sicakligi',\n",
    "    'NDVI'\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_ml = assembler.transform(df)\n",
    "\n",
    "final_data = df_ml.select(\"features\", \"label\")\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"EÄŸitim Verisi: {train_data.count()}\")\n",
    "print(f\"Test Verisi: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787782ee-0f92-4601-a03f-0d8cf301bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Modeli EÄŸitiliyor...\")\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=50, maxDepth=10, seed=42)\n",
    "\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "print(\"Model EÄŸitimi TamamlandÄ±\")\n",
    "\n",
    "print(\"Test verisi Ã¼zerinde tahmin:\")\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d73db-d270-47a1-8bd5-60c80636c47d",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation\n",
    "\n",
    "In this step, we evaluate the performance of the trained Random Forest model using the following metrics:\n",
    "\n",
    "- **Accuracy**: The overall correctness of the model.\n",
    "- **F1 Score**: The harmonic mean of precision and recall.\n",
    "- **Weighted Precision**: The precision of the model, considering class imbalances.\n",
    "- **Weighted Recall**: The recall of the model, considering class imbalances.\n",
    "\n",
    "The evaluation results are displayed as percentages for each metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689c7db-c3c2-4fb1-8f04-d1a1402fe58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "weighted_precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "weighted_recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "print(f\"MODEL BAÅžARI RAPORU\")\n",
    "print(f\"Accuracy)          : %{accuracy*100:.2f}\")\n",
    "print(f\"F1 Skoru           : %{f1_score*100:.2f}\")\n",
    "print(f\"Precision(Kesinlik): %{weighted_precision*100:.2f}\")\n",
    "print(f\"Recall(DuyarlÄ±lÄ±k) : %{weighted_recall*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804c07b-628f-4d5e-ab6a-2388d1e7666f",
   "metadata": {},
   "source": [
    "## Model Training with 100 Trees\n",
    "\n",
    "In this step, we train a new Random Forest model with the following parameters:\n",
    "\n",
    "- **Number of Trees**: 100\n",
    "- **Maximum Depth**: 15\n",
    "\n",
    "The model is evaluated using the same metrics as before: **Accuracy** and **F1 Score**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df138deb-406a-4ed6-b9ef-0287d4e0e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest 100 AÄŸaÃ§...\")\n",
    "\n",
    "rf_v2 = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, maxDepth=15, seed=42)\n",
    "\n",
    "model_v2 = rf_v2.fit(train_data)\n",
    "\n",
    "predictions_v2 = model_v2.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "acc_v2 = evaluator.evaluate(predictions_v2, {evaluator.metricName: \"accuracy\"})\n",
    "f1_v2 = evaluator.evaluate(predictions_v2, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "\n",
    "print(f\"YENÄ° SKORLAR\")\n",
    "print(f\"Accuracy: %{acc_v2*100:.2f}\")\n",
    "print(f\"F1 Skoru: %{f1_v2*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0554c3c3-8f1f-4276-9381-05960265beed",
   "metadata": {},
   "source": [
    "## Feature Importance Visualization\n",
    "\n",
    "In this step, we visualize the importance of each feature in predicting wildfire risk using the trained Random Forest model. The features are sorted by their importance, and a bar plot is generated to show the relative importance of each feature.\n",
    "\n",
    "The most influential factors are identified to understand which variables are driving the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309dde2-69b1-4f45-9075-17d9d22eccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature_list = [\n",
    "    'yukselti', 'egim', 'baki',\n",
    "    'sicaklik', 'ruzgar_hizi', 'bagil_nem', 'yagis', 'toprak_sicakligi',\n",
    "    'NDVI'\n",
    "]\n",
    "\n",
    "importances = model_v2.featureImportances\n",
    "\n",
    "fi_df = pd.DataFrame(list(zip(feature_list, importances)), columns=[\"Feature\", \"Importance\"])\n",
    "fi_df = fi_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(fi_df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=fi_df, palette=\"viridis\")\n",
    "plt.title(\"YangÄ±n Riskini Etkileyen En Ã–nemli FaktÃ¶rler\")\n",
    "plt.xlabel(\"Ã–nem Derecesi\")\n",
    "plt.ylabel(\"FaktÃ¶rler\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d90fa-cadf-471f-8a6a-4e26f83ceb27",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "This section presents the confusion matrix of the trained Random Forest model.\n",
    "It provides a detailed view of the modelâ€™s classification performance by showing\n",
    "the distribution of true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "The heatmap visualization makes it easier to interpret how well the model distinguishes\n",
    "between wildfire and non-wildfire classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968eaaa-a525-4d95-bef8-e584af08190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "conf_matrix_spark = predictions_v2.groupBy(\"label\", \"prediction\").count()\n",
    "conf_matrix_pd = conf_matrix_spark.toPandas()\n",
    "\n",
    "heatmap_data = conf_matrix_pd.pivot(index='label', columns='prediction', values='count').fillna(0)\n",
    "\n",
    "heatmap_data = heatmap_data.sort_index(ascending=True).sort_index(axis=1, ascending=True)\n",
    "\n",
    "heatmap_data.index = [\"GerÃ§ek: Yok (0)\", \"GerÃ§ek: Var (1)\"]\n",
    "heatmap_data.columns = [\"Tahmin: Yok (0)\", \"Tahmin: Var (1)\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='g', cmap='Blues', cbar=False, linewidths=1, linecolor='black')\n",
    "\n",
    "plt.title('ALAZ Model PerformansÄ±: KarÄ±ÅŸÄ±klÄ±k Matrisi', fontsize=16)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8728302-c42b-4a91-9527-e5c77faca88a",
   "metadata": {},
   "source": [
    "## Wildfire Risk Mapping: Manavgat Case Study\n",
    "\n",
    "This section applies the trained Random Forest model to the Manavgat region\n",
    "for July 28, 2021, one of the most severe wildfire events in TÃ¼rkiye.\n",
    "\n",
    "The model generates a spatial wildfire risk map by predicting fire probabilities\n",
    "for each grid point. Observed wildfire locations are overlaid on the map to\n",
    "visually compare predicted risk levels with actual fire occurrences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07edf2c-8922-49b8-9e64-fd5cd6733795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"ðŸ—ºï¸ Manavgat YangÄ±nÄ± (28 Temmuz 2021) verileri Ã§ekiliyor...\")\n",
    "\n",
    "df_manavgat = df.filter(\n",
    "    (col(\"tarih\") == \"2021-07-28\") &\n",
    "    (col(\"latitude\").between(36.5, 37.5)) &\n",
    "    (col(\"longitude\").between(31.0, 32.5))\n",
    ")\n",
    "\n",
    "count = df_manavgat.count()\n",
    "\n",
    "if count > 0:\n",
    "    df_manavgat_ml = assembler.transform(df_manavgat)\n",
    "\n",
    "    predictions_manavgat = model_v2.transform(df_manavgat_ml)\n",
    "\n",
    "    result_pd = predictions_manavgat.select(\"latitude\", \"longitude\", \"probability\", \"label\").toPandas()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    result_pd[\"risk_score\"] = result_pd[\"probability\"].apply(lambda x: x[1])\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    sc = plt.scatter(\n",
    "        result_pd[\"longitude\"], \n",
    "        result_pd[\"latitude\"], \n",
    "        c=result_pd[\"risk_score\"], \n",
    "        cmap=\"RdYlGn_r\",\n",
    "        s=20,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    plt.colorbar(sc, label=\"YangÄ±n Risk Skoru (0-1)\")\n",
    "    plt.title(\"ALAZ Risk HaritasÄ±: Manavgat BÃ¶lgesi (28 Temmuz 2021)\", fontsize=15)\n",
    "    plt.xlabel(\"Boylam\")\n",
    "    plt.ylabel(\"Enlem\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    real_fires = result_pd[result_pd[\"label\"] == 1]\n",
    "    plt.scatter(real_fires[\"longitude\"], real_fires[\"latitude\"], c='black', marker='x', label='GerÃ§ekleÅŸen YangÄ±nlar', s=50)\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tarihi veya koordinatlarÄ± kontrol et.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de21050-2030-44e9-a0b9-79bb321ee85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
